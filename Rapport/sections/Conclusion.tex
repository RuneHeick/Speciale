\chapter{Conclusion}
This master's thesis seek to investigate some of the common approaches used for \ab{NILM}, in order to determine the capabilities and limits. The SmartHG and the \ab{ECO} dataset have been used in order to test some of the hypothesis raised in the study. It is shown that the quality of data collected form a smart meter over a lossy network is high. The greatest quality diminishing factors in the setup is shown to be malfunctioning equipment. Either on the reviving server or at the equipment in the house. It was investigated if a gap filling approach could improve the quality. Small errors on less than 5 samples is fairly easy to correct. Larger gaps is harder to correct. When using the corrected data in appliance recognition algorithms it is shown that more advanced methods of gap filling does not improve the performance compared to a simple linear interpolation. That said does the linear interpolation improve the performance, in comparison to no effort of correction. 

It is shown that devices that have a relative high consumption is easier to detect than appliances that does only consume a little amount of energy. This is due to the greater chance of uniqueness for these types of appliances. The \df{completeness} and \df{complexity} of statistical disaggregation models where investigated. This showed that one of the factors that had a big impact on the performance was the number of devices in the environment. This was due to \df{appliance interference} between the devices. One way of minimizing the impact of \df{appliance interference} is to look at each phase individually, to minimize the number of appliances in each environment. 

In general is a acceptable performance only obtained on the top consumers in the home. Therefore can the relative consumption of a appliance in compensation to the whole house consumption be used as a quality metric. In the report is a small case project illustrating how a \df{service provider} would be able to sell information about the usage behaviour of televisions in a city. It is shown that for this type of application is the performance acceptable, where detecting small devices like lamps and stereos is way more error prone. 

The \ab{NILM} disaggregation algorithms based on machine learning have a training period prior to deployment. In the training period is statistical disaggregation models learned, that makes the algorithms capable of appliance disaggregation. It is showed that the best performance is achieved when learning in the deployment environment. This is since model learned in a other environment is missing information about the \df{background consumption} in the deployment environment. 

The \ab{NILM} technology seems limited by the low sample rates expected from a smart grid. It is shown that the faster the sample rate, the better the performance. On approach that showed  promise in improving the performance is the \df{norm filter}. The \df{norm filter} enforces the disaggregation with the rules of normal expected use of a appliance. This filters unrealistic event from the disaggregation.