\chapter{NILM As An Application} 
The last couple of years have the number of smart meters installed in residential houses increased drastically. The motivation for installing smart meters in the different houses have been to better understand energy consumption, in order to better plan energy distribution and production. Whit the smart meter came a golden opportunity for \ab{NILM}, since the equipment and infrastructure needed to measure the consumption and transfer the results to the internet was available in many households. 

The applications proposed in many of the articles published about \ab{NILM} focuses on energy management. Either it is for the electricity producers, that needs it to better predict consumption\fxnote{find ref}, or it is for the resident of the house that can optimize power usage to obtain savings. Even though these are fine examples of the potential usages of \ab{NILM} there might also exist a opportunity for the electric companies to sell the \ab{NILM} information and act as a data broker. This chapter contains a small case study to illustrate this point. 

\fxnote{Many of these claims need refs}

\section{The TV Viewing Habits Case}
The case setting is a small town, that have a number of households and a electric company supplying energy to the city.For this case data from the SmartHG dataset is used to simulate a small town with 4 houses. The houses selected for this case is 10, 13, 18 and 23  since they contain a TV that are relatively dominant, as discussed in section \ref{sec:MMIRTSM}. 

\begin{figure}[H]
\begin{picture}(0,150)
\put(100,0){\includegraphics[width=0.6\textwidth]{billeder/CaseIlu.png}}

\put(177,110){Network}

\put(122,62){\color{white} \textbf{10}}
\put(174,62){\color{white} \textbf{13}}
\put(226,62){\color{white} \textbf{18}}
\put(276,62){\color{white} \textbf{23}}
\put(200,0){Power Line}

\end{picture}
\caption{}
\label{fig:CaseSetup}
\end{figure}

In the city setup is illustrated in figure \ref{fig:CaseSetup}. The figure is illustrated how the power company supplies power to the houses. All the houses have smart meters, and is informing the power company about the current consumption of each house, using some network. This is a fairly simplified example of a smart grid, that exists in many cities today. In this case it is assumed that the electric company receives information about the consumption of the houses each 30 seconds, as in the SmartHG dataset. Even though many smart meters today are capable of delivering information at this speed, it is more common to only get information each hour. This is mainly because the information is used to regulate distribution and production, which is a slow process that would not improve by faster update rates.  

The electric companies collect the information, and by using \ab{NILM} can calculate statistical information about the town. In the fictive case is a local TV station interested in knowing what time a day the citizens of the town watches TV, in a specific period, in order to improve some aspect of there product. Is the the electric company able to deliver this information? 

\section{Methodology}
The aim of this case is to illustrate the potential of this kind of application for an electric company. Therefore is data analysis conducted in a manner, that illustrates how a power company could do it. This means that only the main meter information is used in the analysis, and the sub-meter information is only used to validate the results.  The goal is for the electric company to disaggregate the TV signals from the main meter signal, in order to use it in some statistical analysis. 

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{billeder/Electric company method.png}
\caption{}
\label{fig:ECM}
\end{figure}

This process is illustrated on figure \ref{fig:ECM}. It is assumed that the power company have access to a very general statistical model of the TV. This model can come from some outside database, or be one that the electric company developed them selves. The first step is to create a household specific model, that is a specialisation of the general model. This could be done with sub-meter data, but to make the experiment more realistic is the fitting of the model done using only the aggregated data from the main meter. This is done using the same method as developed for the Parson algorithm \citep{RefWorks:28}, where periods where an appliance is turned on and off without any other appliances changing states, is detected. This on/off single event fragments is then mapped to specific appliances using the general model. When enough on/off single event fragments have been collected can this information be used to fit a more specific model. This can happen in a contentiously manner, where the specific model is improved as more data is collected.  

Using the specific models disaggregation of the main meter signal can now be achieved. The statistical models selected in this case is the \ab{FHMM}. As discussed in section \ref{sec:NOISE}, the models alone gives a very error prone signal in the \ab{FHMM}. Therefore is the signal feed through a norm filter. As discussed in \ref{sec:NormFilter} can the information about how a user normally would use the appliance be used to filter the disaggregated data. 

The result of this process is a appliance usage pattern, that can be used by the electric company to derive various statistical properties.  

The experiment is conducted with 4 weeks of data been used to fit TV specific models for each house. The analysis for the TV station is conducted over a period of 6 weeks, that is not overlapping with the initial 4 training weeks. 

\section{Results}
The viewing habits of the small town obtained by the disaggregation analysis is compared with the actual viewing habit obtained from the sub-meter data. In figure \ref{fig:WHW} is the results shown for the first week.   

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{billeder/Viewership.png}
\caption{}
\label{fig:WHW}
\end{figure}

In the figure is seen the viewership that tells how many in the city is watching TV at a given time. The green line is the actual viewership, where the blue is the viewership reported by the electric company. The results differer, as one would expect, since the disaggregation process in a noisy environment is a hard task. The general trends that many are watching TV in the evening, and not that many in the morning, is still represented nicely. This illustrates that the general trends of the viewership is maintained in the disaggregated signal, and this is commonly what is important for this kind of costumer statistics. 

In table \ref{tab:CaseRes} is the average number of viewers in 3 hour timeslots shown. The results shown in the table is the average of all 6 weeks, split up in the different weekdays. 

\input{tables/TVCaseResTab}

This illustrates that the true trends in the information is maintained. The results indicates that it is in some degree possible to obtain user information from the disaggregated data. The TV is a relative hard appliance to detect, since there is many different types. The success in this experiment is partly due to the fact that the TV was some of the main consumers of the houses selected, and they had a pure Type-I behaviour. 

\section{Chapter Discussion}

