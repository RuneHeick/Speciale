@misc{RefWorks:46,
     year={2011},
     month={10/11/2011},
     title={The electricity grid: A history},
     volume={2016},
     number={04/04},
     url={http://burnanenergyjournal.com/the-electricity-grid-a-history/}
}
@article{RefWorks:17,
     author={Ahmed Zoha and Alexander Gluhak and Muhammad Ali Imran and Sutharshan Rajasegarar },
     year={2012},
     title={Non-Intrusive Load Monitoring Approaches for Disaggregated Energy Sensing: A Survey},
     journal={Sensors},
     volume={12},
     number={12},
     pages={16838-16866},
     note={Appliance Load Monitoring (ALM) is essential for energy management solutions, allowing them to obtain appliance-specific energy consumption statistics that... Appliance Load Monitoring (ALM) is essential for energy management solutions, allowing them to obtain appliance-specific energy consumption statistics that can...},
     abstract={Appliance Load Monitoring (ALM) is essential for energy management solutions, allowing them to obtain appliance-specific energy consumption statistics that can further be used to devise load scheduling strategies for optimal energy utilization. Fine-grained energy monitoring can be achieved by deploying smart power outlets on every device of interest; however it incurs extra hardware cost and installation complexity. Non-Intrusive Load Monitoring (NILM) is an attractive method for energy disaggregation, as it can discern devices from the aggregated data acquired from a single point of measurement. This paper provides a comprehensive overview of NILM system and its associated methods and techniques used for disaggregated energy sensing. We review the state-of-the art load signatures and disaggregation algorithms used for appliance recognition and highlight challenges and future research directions.},
     keywords={Non-Intrusive Load Monitoring (NILM); Intrusive Load Monitoring (ILM); load signatures; disaggregation algorithms; energy management; Chemistry; QD71-142; T1-995; Technology (General); Analytical chemistry; Science; QD1-999; Technology},
     isbn={1424-8220},
     language={English}
}
@misc{RefWorks:42,
     author={{NIST} Smart Grid and Cyber-Physical Systems Program Office},
     year={2015},
     month={December 23, 2015},
     title={Smart Grid},
     volume={2016},
     number={2 April},
     url={http://www.nist.gov/smartgrid/}
}
@@article{RefWorks:24,
     author={M. Baranski and J. Voss},
     year={2004},
     title={Genetic algorithm for pattern detection in NIALM systems},
     booktitle={Systems, Man and Cybernetics, 2004 IEEE International Conference on},
     volume={4},
     pages={3462-3468 vol.4},
     note={ID: 1},
     isbn={1062-922X}
}
@@article{RefWorks:21,
author =       {Nipun Batra and Jack Kelly and Oliver Parson and Haimonti Dutta and William Knottenbelt and Alex Rogers and Amarjeet Singh and Mani Srivastava},
month =       {2014-04-15},
title =       {NILMTK: An Open Source Toolkit for Non-intrusive Load Monitoring},
url =       {http://arxiv.org/abs/1404.3878},
note =       {Type: text},
abstract =       {Non-intrusive load monitoring, or energy disaggregation, aims to separatehousehold energy consumption data collected from a single point of measurementinto appliance-level consumption data. In recent years, the field has rapidlyexpanded due to increased interest as national deployments of smart meters havebegun in many countries. However, empirically comparing disaggregationalgorithms is currently virtually impossible. This is due to the different datasets used, the lack of reference implementations of these algorithms and thevariety of accuracy metrics employed. To address this challenge, we present theNon-intrusive Load Monitoring Toolkit (NILMTK); an open source toolkit designedspecifically to enable the comparison of energy disaggregation algorithms in areproducible manner. This work is the first research to compare multipledisaggregation approaches across multiple publicly available data sets. Ourtoolkit includes parsers for a range of existing data sets, a collection ofpreprocessing algorithms, a set of statistics for describing data sets, tworeference benchmark disaggregation algorithms and a suite of accuracy metrics.We demonstrate the range of reproducible analyses which are made possible byour toolkit, including the analysis of six publicly available data sets and theevaluation of both benchmark disaggregation algorithms across such data sets.; Comment: To appear in the fifth International Conference on Future Energy Systems (ACM e-Energy), Cambridge, UK. 2014},
keywords =       {Statistics - Applications}
}
@@article{RefWorks:32,
author =       {Nipun Batra and Jack Kelly and Oliver Parson and Haimonti Dutta and William Knottenbelt and Alex Rogers and Amarjeet Singh and Mani Srivastava},
month =       {2014-04-15},
title =       {NILMTK: An Open Source Toolkit for Non-intrusive Load Monitoring},
url =       {http://arxiv.org/abs/1404.3878},
note =       {Type: text},
abstract =       {Non-intrusive load monitoring, or energy disaggregation, aims to separatehousehold energy consumption data collected from a single point of measurementinto appliance-level consumption data. In recent years, the field has rapidlyexpanded due to increased interest as national deployments of smart meters havebegun in many countries. However, empirically comparing disaggregationalgorithms is currently virtually impossible. This is due to the different datasets used, the lack of reference implementations of these algorithms and thevariety of accuracy metrics employed. To address this challenge, we present theNon-intrusive Load Monitoring Toolkit (NILMTK); an open source toolkit designedspecifically to enable the comparison of energy disaggregation algorithms in areproducible manner. This work is the first research to compare multipledisaggregation approaches across multiple publicly available data sets. Ourtoolkit includes parsers for a range of existing data sets, a collection ofpreprocessing algorithms, a set of statistics for describing data sets, tworeference benchmark disaggregation algorithms and a suite of accuracy metrics.We demonstrate the range of reproducible analyses which are made possible byour toolkit, including the analysis of six publicly available data sets and theevaluation of both benchmark disaggregation algorithms across such data sets.; Comment: To appear in the fifth International Conference on Future Energy Systems (ACM e-Energy), Cambridge, UK. 2014},
keywords =       {Statistics - Applications}
}
@@article{RefWorks:26,
     author={Christian Beckel and Wilhelm Kleiminger and Romano Cicchetti and Thorsten Staake and Silvia Santini},
     year={2014},
     month={nov},
     title={The ECO Data Set and the Performance of Non-Intrusive Load Monitoring Algorithms},
     booktitle={Proceedings of the 1st ACM International Conference on Embedded Systems for Energy-Efficient Buildings (BuildSys 2014). Memphis, TN, USA},
     publisher={ACM},
     pages={80-89}
}
@@article{RefWorks:19,
author =       {Roberto Bonfigli and Stefano Squartini and Marco Fagiani and Francesco Piazza},
year =       {2015},
title =       {Unsupervised algorithms for non-intrusive load monitoring: An up-to-date overview},
journal =       {2015 IEEE 15th International Conference on Environment and Electrical Engineering (EEEIC)},
pages =       {1175-1180},
note =       {Research on Smart Grids has recently focused on the energy monitoring issue, with the objective to maximize the user consumption awareness in building contexts...},
abstract =       {Research on Smart Grids has recently focused on the energy monitoring issue, with the objective to maximize the user consumption awareness in building contexts on one hand, and to provide a detailed description of customer habits to the utilities on the other. One of the hottest topic in this field is represented by Non-Intrusive Load Monitoring (NILM): it refers to those techniques aimed at decomposing the consumption aggregated data acquired at a single point of measurement into the diverse consumption profiles of appliances operating in the electrical system under study. The focus here is on unsupervised algorithms, which are the most interesting and of practical use in real case scenarios. Indeed, these methods rely on a sustainable amount of a-priori knowledge related to the applicative context of interest, thus minimizing the user intervention to operate, and are targeted to extract all information to operate directly from the measured aggregate data. This paper reports and describes the most promising unsupervised NILM methods recently proposed in the literature, by dividing them into two main categories: load classification and source separation approaches. An overview of the public available dataset used on purpose and a comparative analysis of the algorithms performance is provided, together with a discussion of challenges and future research directions.},
keywords =       {Measurement; load classification methods; smart grid; Algorithm design and analysis; smart grids; unsupervised NILM overview; load forecasting; energy monitoring; Aggregates; source separation; load classification; Hidden Markov models; energy dataset overview; non-intrusive load monitoring; unsupervised algorithms; source separation methods; consumption aggregated data; Home appliances; Data models},
language =       {English}
}
@article{RefWorks:33,
     author={Dario Bonino and Fulvio Corno and Luigi De Russis},
     year={2012},
     title={Home energy consumption feedback: A user survey},
     journal={Energy and Buildings},
     volume={47},
     pages={383-393},
     keywords={Survey; In-home display; IHD; User interface; Energy; Architecture and energy conservation; Surveys; Energy consumption},
     isbn={0378-7788},
     language={English}
}
@article{RefWorks:11,
     author={P. J. S. G. Ferreira},
     year={1994},
     title={Interpolation and the discrete Papoulis-Gerchberg algorithm},
     journal={IEEE Transactions on Signal Processing},
     volume={42},
     number={10},
     pages={2596-2606},
     note={Analyze the performance of an iterative algorithm, similar to the discrete Papoulis-Gerchberg algorithm, and which can be used to recover missing samples in...   An analysis of the performance of an iterative algorithm that can be used to recover missing samples in finite-length records of band-limited data.No...},
     abstract={Analyze the performance of an iterative algorithm, similar to the discrete Papoulis-Gerchberg algorithm, and which can be used to recover missing samples in finite-length records of band-limited data. No assumptions are made regarding the distribution of the missing samples, in contrast with the often studied extrapolation problem, in which the known samples are grouped together. Indeed, it is possible to regard the observed signal as a sampled version of the original one, and to interpret the reconstruction result studied as a sampling result. The authors show that the iterative algorithm converges if the density of the sampling set exceeds a certain minimum value which naturally increases with the bandwidth of the data. They give upper and lower bounds for the error as a function of the number of iterations, together with the signals for which the bounds are attained. Also, they analyze the effect of a relaxation constant present in the algorithm on the spectral radius of the iteration matrix. From this analysis they infer the optimum value of the relaxation constant. They also point out, among all sampling sets with the same density, those for which the convergence rate of the recovery algorithm is maximum or minimum. For low-pass signals it turns out that the best convergence rates result when the distances among the missing samples are a multiple of a certain integer. The worst convergence rates generally occur when the missing samples are contiguous.},
     keywords={Extrapolation; missing samples; signal processing; Convergence; spectral radius; iteration matrix; sampling set density; Bandwidth; error; iterative methods; band-limited data; reconstruction result; Iterative algorithms; Algorithm design and analysis; interpolation; discrete Papoulis-Gerchberg algorithm; Performance analysis; Image reconstruction; recovery algorithm; convergence of numerical methods; finite-length records; iterative algorithm; relaxation constant; convergence rate; Discrete Fourier transforms; Sampling methods; low-pass signals; Iterative methods (Mathematics); Research; Signal reconstruction/Mathematical models},
     isbn={1053-587X},
     language={English}
}
@article{RefWorks:37,
     author={G. W. Hart},
     year={1989},
     title={Residential energy monitoring and computerized surveillance via utility power flows},
     journal={IEEE Technology and Society Magazine},
     volume={8},
     number={2},
     pages={12-16},
     note={ID: 1},
     keywords={computerised monitoring; power system computer control; computerized surveillance; nonintrusive appliance load monitoring technique; residential energy monitoring; utility power flows; Computerized monitoring; Home appliances; Privacy; Surveillance},
     isbn={0278-0097}
}
@article{RefWorks:20,
     author={Zoubin Ghahramani and Michael I. Jordan},
     year={1997},
     title={Factorial Hidden Markov Models},
     journal={Machine Learning},
     volume={29},
     number={2},
     pages={245-273},
     note={Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data. In an HMM, information...   Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data. In an HMM, information...},
     abstract={Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data. In an HMM, information about the past is conveyed through a single discrete variable?the hidden state. We discuss a generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner. We describe an exact algorithm for inferring the posterior probabilities of the hidden state variables given the observations, and relate it to the forward?backward algorithm for HMMs and to algorithms for more general graphical models. Due to the combinatorial nature of the hidden state representation, this exact algorithm is intractable. As in other intractable systems, approximate inference can be carried out using Gibbs sampling or variational methods. Within the variational framework, we present a structured approximation in which the the state variables are decoupled, yielding a tractable algorithm for learning the parameters of the model. Empirical comparisons suggest that these approximations are efficient and provide accurate alternatives to the exact methods. Finally, we use the structured approximation to model Bach's chorales and show that factorial HMMs can capture statistical structure in this data set which an unconstrained HMM cannot.},
     keywords={mean field theory; graphical models; time series; Hidden Markov models; Automation and Robotics; Computer Science, general; Bayesian networks; Computer Science; Artificial Intelligence (incl. Robotics); EM algorithm; Studies; Variables; Mathematical models; Algorithms; Analysis},
     isbn={0885-6125},
     language={English}
}
@article{RefWorks:41,
     author={Christopher Greer and David A. Wollman and Dean E. Prochaska and Paul A. Boynton and Jeffrey A. Mazer and Cuong T. Nguyen and Gerald J. FitzPatrick and Thomas L. Nelson and Galen H. Koepke and Allen R. Hefner Jr and Victoria Y. Pillitteri and Tanya L. Brewer and Nada T. Golmie and David H. Su and Allan C. Eustis and David G. Holmberg and Steven T. Bushby},
     year={2014},
     month={oct},
     title={NIST Framework and Roadmap for Smart Grid Interoperability Standards, Release 3.0},
     institution={National Institute of Standards and Technology},
     pages={123-146},
     url={http://dx.doi.org/10.6028/NIST.SP.1108r3}
}
@article{RefWorks:39,
     author={Ulrich Greveler and Peter Glosekotterz and Benjamin Justusy and Dennis Loehr},
     year={2012},
     title={Multimedia content identification through smart meter power usage profiles},
     journal={Proceedings of the International Conference on Information and Knowledge Engineering (IKE)},
     pages={1}
}
@misc{RefWorks:7,
author =       {{\relax ISO 19157:2013}},
year =       {2013-12-15},
title =       {Geographic information -- Data quality}
}
@misc{RefWorks:5,
author =       {{\relax ISO 8402:1994}},
year =       {1994-03-24},
title =       {Quality management and quality assurance -- Vocabulary}
}
@article{RefWorks:34,
     author={Aqeel H. Kazmi and Michael J. O'Grady and Gregory M.P. O' Hare},
     editor={Mehdi Khosrow-Pour},
     year={2015},
     title={Towards Low-Cost Energy Monitoring},
     publisher={IGI Global},
     address={Hershey, PA, USA},
     pages={2965-2970},
     note={ID: 112719},
     abstract={A number of energy problems including limited energy resources, increased energy demand, and rising energy prices, have motivated energy conservation in the residential and commercial sectors. Access to real-time energy usage information is perceived as a prerequisite for energy usage reductions. A variety of computational approaches have been proposed to monitor energy usage within buildings. Currently, Non-intrusive Load Monitoring (NILM) is perceived as the most cost-effective and scalable solution. In this article, a technological profile of this technique is constructed through the provision of key background developments, revision of existing solutions, consideration of outstanding problems, and identification of some pertinent future research directions.},
     isbn={9781466658882},
     url={http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-4666-5888-2.ch289}
}
@article{RefWorks:2,
author =       {Steve Kelling and Daniel Fink and Frank A. La Sorte and Alison Johnston and Nicholas E. Bruns and Wesley M. Hochachka},
month =       {2015-10-27; 2015-11},
title =       {Taking a 'Big Data' approach to data quality in a citizen science project},
note =       {Type: Text; © The Author(s) 2015; Open AccessThis article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.},
abstract =       {Data from well-designed experiments provide the strongest evidence of causation in biodiversity studies. However, for many species the collection of these data is not scalable to the spatial and temporal extents required to understand patterns at the population level. Only data collected from citizen science projects can gather sufficient quantities of data, but data collected from volunteers are inherently noisy and heterogeneous. Here we describe a ?Big Data? approach to improve the data quality in eBird, a global citizen science project that gathers bird observations. First, eBird?s data submission design ensures that all data meet high standards of completeness and accuracy. Second, we take a ?sensor calibration? approach to measure individual variation in eBird participant?s ability to detect and identify birds. Third, we use species distribution models to fill in data gaps. Finally, we provide examples of novel analyses exploring population-level patterns in bird distributions.},
keywords =       {Article},
language =       {en}
}
@article{RefWorks:25,
author =       {Jack Kelly and William Knottenbelt},
month =       {2015-07-23; 2015-09-28},
title =       {Neural NILM: Deep Neural Networks Applied to Energy Disaggregation},
url =       {http://arxiv.org/abs/1507.06594},
note =       {Type: text},
abstract =       {Energy disaggregation estimates appliance-by-appliance electricityconsumption from a single meter that measures the whole home's electricitydemand. Recently, deep neural networks have driven remarkable improvements inclassification performance in neighbouring machine learning fields such asimage classification and automatic speech recognition. In this paper, we adaptthree deep neural network architectures to energy disaggregation: 1) a form ofrecurrent neural network called `long short-term memory' (LSTM); 2) denoisingautoencoders; and 3) a network which regresses the start time, end time andaverage power demand of each appliance activation. We use seven metrics to testthe performance of these algorithms on real aggregate power data from fiveappliances. Tests are performed against a house not seen during training andagainst houses seen during training. We find that all three neural nets achievebetter F1 scores (averaged over all five appliances) than either combinatorialoptimisation or factorial hidden Markov models and that our neural netalgorithms generalise well to an unseen house.; Comment: To appear in ACM BuildSys'15, November 4--5, 2015, Seoul},
keywords =       {Computer Science - Neural and Evolutionary Computing; I; 2; 6; 5}
}
@article{RefWorks:47,
     author={Egon Kidmose and Emad Samuel Malki Ebeid and Rune Hylsberg Jacobsen},
     year={2015},
     title={A Framework for Detecting and Translating User Behavior from Smart Meter Data},
     booktitle={Smart 2015: The fourth International conference on Smart Systems, Devices and Technologies},
     publisher={International Academy, Research, and Industry Association ( IARIA )},
     pages={71-74},
     abstract={The European adoption of smart electricity meters triggers the developments of new value-added service for smart energy and optimal consumption. Recently, several algorithms and tools have been built to analyze smart meter?s data. This paper introduces an open framework and prototypes for detecting and presenting user behavior from its smart meter power consumption data. The framework aims at presenting the detected user behavior in natural language reports. In order to validate the proposed framework, an experiment has been performed and the results have been presented.}
}
@article{RefWorks:27,
     author={Wilhelm Kleiminger and Christian Beckel and Silvia Santini},
     year={2015},
     month={sep},
     title={Household Occupancy Monitoring Using Electricity Meters},
     booktitle={Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2015)},
     address={Osaka, Japan}
}
@article{RefWorks:22,
     author={J. Z. Kolter and Tommi Jaakkola},
     editor={Neil D. Lawrence and Mark A. Girolami},
     year={2012},
     title={Approximate Inference in Additive Factorial HMMs with Application to Energy Disaggregation},
     booktitle={Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS-12)}},
     volume={22},
     pages={1472-1482},
     url={http://jmlr.csail.mit.edu/proceedings/papers/v22/zico12/zico12.pdf}
}
@article{RefWorks:15,
     author={D. Kondrashov and M. Ghil},
     year={2006},
     title={Spatio-temporal filling of missing points in geophysical data sets},
     journal={Nonlinear Processes in Geophysics},
     volume={13},
     number={2},
     pages={151-159},
     note={The majority of data sets in the geosciences are obtained from observations and measurements of natural systems, rather than in the laboratory. These data... The majority of data sets in the geosciences are obtained from observations and measurements of natural systems, rather than in the laboratory. These data sets...},
     abstract={The majority of data sets in the geosciences are obtained from observations and measurements of natural systems, rather than in the laboratory. These data sets are often full of gaps, due to to the conditions under which the measurements are made. Missing data give rise to various problems, for example in spectral estimation or in specifying boundary conditions for numerical models. Here we use Singular Spectrum Analysis (SSA) to fill the gaps in several types of data sets. For a univariate record, our procedure uses only temporal correlations in the data to fill in the missing points. For a multivariate record, multi-channel SSA (M-SSA) takes advantage of both spatial and temporal correlations. We iteratively produce estimates of missing data points, which are then used to compute a self-consistent lag-covariance matrix; cross-validation allows us to optimize the window width and number of dominant SSA or M-SSA modes to fill the gaps. The optimal parameters of our procedure depend on the distribution in time (and space) of the missing data, as well as on the variance distribution between oscillatory modes and noise. The algorithm is demonstrated on synthetic examples, as well as on data sets from oceanography, hydrology, atmospheric sciences, and space physics: global sea-surface temperature, flood-water records of the Nile River, the Southern Oscillation Index (SOI), and satellite observations of relativistic electrons.[PUBLICATION ABSTRACT]},
     keywords={Data bases; Spectrum analysis; Geophysics; Physics; Geophysics. Cosmic physics; QC1-999; Geology; QE1-996.5; QC801-809; Science},
     isbn={1023-5809 1607-7946},
     language={English}
}
@article{RefWorks:4,
author =       {M. Meijer and L. A. E. Vullings and J. D. Bulens and F. I. Rip and M. Boss and G. Hazeu and M. Storm},
month =       {2015-08-01T00:00:00Z},
title =       {SPATIAL DATA QUALITY AND A WORKFLOW TOOL},
url =       {https://doaj.org/article/2d94274972fe46a0b598b7f0569ee5b3},
note =       {Type: article; CC BY},
abstract =       {Although by many perceived as important, spatial data quality has hardly ever been taken centre stage unless something went wrong due to bad quality. However, we think this is going to change soon. We are more and more relying on data driven processes and due to the increased availability of data, there is a choice in what data to use. How to make that choice? We think spatial data quality has potential as a selection criterion.

In this paper we focus on how a workflow tool can help the consumer as well as the producer to get a better understanding about which product characteristics are important. For this purpose, we have developed a framework in which we define different roles (consumer, producer and intermediary) and differentiate between product specifications and quality specifications. A number of requirements is stated that can be translated into quality elements. We used case studies to validate our framework. This framework is designed following the fitness for use principle. Also part of this framework is software that in some cases can help ascertain the quality of datasets.},
keywords =       {Technology; T; Engineering (General); Civil engineering (General); TA1-2040; Applied optics; Photonics; TA1501-1820},
language =       {EN}
}
@article{RefWorks:8,
author =       {M. Meijer and L. A. E. Vullings and J. D. Bulens and F. I. Rip and M. Boss and G. Hazeu and M. Storm},
month =       {2015-08-01T00:00:00Z},
title =       {SPATIAL DATA QUALITY AND A WORKFLOW TOOL},
url =       {https://doaj.org/article/2d94274972fe46a0b598b7f0569ee5b3},
note =       {Type: article; CC BY},
abstract =       {Although by many perceived as important, spatial data quality has hardly ever been taken centre stage unless something went wrong due to bad quality. However, we think this is going to change soon. We are more and more relying on data driven processes and due to the increased availability of data, there is a choice in what data to use. How to make that choice? We think spatial data quality has potential as a selection criterion.

In this paper we focus on how a workflow tool can help the consumer as well as the producer to get a better understanding about which product characteristics are important. For this purpose, we have developed a framework in which we define different roles (consumer, producer and intermediary) and differentiate between product specifications and quality specifications. A number of requirements is stated that can be translated into quality elements. We used case studies to validate our framework. This framework is designed following the fitness for use principle. Also part of this framework is software that in some cases can help ascertain the quality of datasets.},
keywords =       {Technology; T; Engineering (General); Civil engineering (General); TA1-2040; Applied optics; Photonics; TA1501-1820},
language =       {EN}
}
@article{RefWorks:45,
     author={Lucy Maggs Maggs and Alicia Painter},
     year={2016},
     month={31/3/2016},
     title={Smart Energy GB response to DECC quarterly report on smart meter installations},
     volume={2016},
     number={04/04},
     url={https://www.smartenergygb.org/en/the-bigger-picture/about-smart-energy-gb/press-centre/press-releases/press-release-folder/decc-report-march-2016}
}
@article{RefWorks:35,
     author={Stephen Makonin and Fred Popowich},
     year={2014},
     title={Nonintrusive load monitoring (NILM) performance evaluation},
     journal={Energy Efficiency},
     volume={8},
     number={4},
     pages={809-814},
     abstract={Nonintrusive load monitoring (NILM), sometimes referred to as load disaggregation, is the process of determining what loads or appliances are running in a house from analysis of the power signal of the whole-house power meter. As the popularity of NILM grows, we find that there is no consistent way the researchers are measuring and reporting accuracies. In this short communication, we present a unified approach that would allow for consistent accuracy testing."},
     isbn={1570-6478},
     url={http://dx.doi.org/10.1007/s12053-014-9306-2}
}
@book{RefWorks:10,
     author={Dimitris G. Manolakis and Vinay K. Ingle},
     year={2011},
     title={Applied digital signal processing : theory and practice},
     publisher={Cambridge University Press},
     address={New York},
     pages={991},
     keywords={elektronisk signalbehandling; Signal processing - Digital techniques; digital signalbehandling; digital signal processing; DSP; elektriske kredsløb; LTI systems; discrete-time-systems; multirate signal processing; electronic circuits},
     isbn={9780521110020},
     language={eng}
}
@article{RefWorks:13,
     author={Manuel Marques and Alexandre Neves and JorgeS Marques and JoÃ£o Sanches},
     year={2006},
     title={The Papoulis-Gerchberg Algorithm with Unknown Signal Bandwidth},
     volume={4141},
     pages={436-445},
     isbn={978-3-540-44891-4},
     language={English},
     url={http://dx.doi.org/10.1007/11867586_41}
}
@article{RefWorks:36,
     author={Stephen McLaughlin and Patrick McDaniel and William Aiello},
     year={2011},
     title={Protecting Consumer Privacy from Electric Load Monitoring},
     booktitle={Proceedings of the 18th ACM Conference on Computer and Communications Security},
     series={CCS '11},
     publisher={ACM},
     address={New York, NY, USA},
     location={Chicago, Illinois, USA},
     pages={87-98},
     keywords={load monitor; privacy; smart meter},
     isbn={978-1-4503-0948-6},
     url={http://doi.acm.org/10.1145/2046707.2046720}
}
@article{RefWorks:16,
author =       {A. Moghtaderi and P. Borgnat and P. Flandrin},
year =       {2012},
title =       {Gap-filling by the empirical mode decomposition},
journal =       {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
pages =       {3821-3824},
note =       {We propose a novel gap-filling technique, based on the empirical mode decomposition (EMD). The idea is that a signal with missing data can be decomposed into a...},
abstract =       {We propose a novel gap-filling technique, based on the empirical mode decomposition (EMD). The idea is that a signal with missing data can be decomposed into a set of intrinsic mode functions (IMFs) with missing data. Filling the gaps in each IMF should be easier than filling the gaps in the original signal. This is because each IMF varies much more slowly than the original signal, and also because the IMFs are known to have useful regularity properties. We demonstrate the performance of our technique on environmental pollutant data.},
keywords =       {empirical mode decomposition; gap-filling technique; Signal processing algorithms; Spectral analysis; Zirconium; signal processing; signal restoration; Interpolation; Indexes; Signal reconstruction; missing data decomposition; environmental pollutant data; EMD; Splines (mathematics); IMF},
isbn =       {1520-6149; 1467300454 9781467300452},
language =       {English}
}
@article{RefWorks:43,
     author={James A. Momoh},
     year={2012},
     title={Smart grid : fundamentals of design and analysis},
     publisher={Wiley},
     address={Hoboken, N.J.},
     pages={1-29},
     keywords={Electric power distribution; TECHNOLOGY & ENGINEERING / Power Resources / General; Electric power distribution - Automation; smart grid; intelligente netværk; intelligente reguleringssystemer; intelligente systemer; elforsyning; forsyningsnet; el-fordelingsnet; el-installationer; elnet; design; energilagring; netværk; vedvarende energi},
     isbn={9780470889398},
     language={eng}
}
@article{RefWorks:3,
author =       {N. Regnauld},
month =       {2015-08-01T00:00:00Z},
title =       {GENERALISATION AND DATA QUALITY},
url =       {https://doaj.org/article/c22b25fbc7db468581f974b22d0f4640},
note =       {Type: article; CC BY},
abstract =       {The quality of spatial data has a massive impact on its usability. It is therefore critical to both the producer of the data and its users.In this paper we discuss the close links between data quality and the generalisation process. The quality of the source data has aneffect on how it can be generalised, and the generalisation process has an effect on the quality of the output data. Data qualitytherefore needs to be kept under control. We explain how this can be done before, during and after the generalisation process, usingthree of 1Spatial?s software products: 1Validate for assessing the conformance of a dataset against a set of rules, 1Integrate forautomatically fixing the data when non-conformances have been detected and 1Generalise for controlling the quality during thegeneralisation process. These tools are very effective at managing data that need to conform to a set of quality rules, the mainremaining challenge is to be able to define a set of quality rules that reflects the fitness of a dataset for a particular purpose.},
keywords =       {Technology; T; Engineering (General); Civil engineering (General); TA1-2040; Applied optics; Photonics; TA1501-1820},
language =       {EN}
}
@article{RefWorks:28,
     author={Oliver Parson and Siddhartha Ghosh and Mark Weal and Alex Rogers},
     year={2012},
     month={July},
     title={Non-intrusive load monitoring using prior models of general appliance types},
     booktitle={Proceedings of theTwenty-Sixth Conference on Artificial Intelligence (AAAI-12)},
     pages={356-362},
     abstract={Non-intrusive appliance load monitoring is the process of disaggregating a household's total electricity consumption into its contributing appliances. In this paper we propose an approach by which individual appliances can be iteratively separated from an aggregate load. Unlike existing approaches, our approach does not require training data to be collected by sub-metering individual appliances, nor does it assume complete knowledge of the appliances present in the household. Instead, we propose an approach in which prior models of general appliance types are tuned to specific appliance instances using only signatures extracted from the aggregate load. The tuned appliance models are then used to estimate each appliance's load, which is subsequently subtracted from the aggregate load. This process is applied iteratively until all appliances for which prior behaviour models are known have been disaggregated. We evaluate the accuracy of our approach using the REDD data set, and show the disaggregation performance when using our training approach is comparable to when sub-metered training data is used. We also present a deployment of our system as a live application and demonstrate the potential for personalised energy saving feedback.},
     url={http://eprints.soton.ac.uk/336812/}
}
@article{RefWorks:6,
     author={G. Pastorello and D. Agarwal and T. Samak and C. Poindexter and B. Faybishenko and D. Gunter and R. Hollowgrass and D. Papale and C. Trotta and A. Ribeca and E. Canfora},
     year={2014},
     title={Observational Data Patterns for Time Series Data Quality Assessment},
     booktitle={e-Science (e-Science), 2014 IEEE 10th International Conference on},
     volume={1},
     pages={271-278},
     note={ID: 1}
}
@article{RefWorks:30,
     author={Shwetak N. Patel and Thomas Robertson and Julie A. Kientz and Matthew S. Reynolds and Gregory D. Abowd},
     year={2007},
     title={At the Flick of a Switch: Detecting and Classifying Unique Electrical Events on},
     booktitle={the Residential Power Line,” Proc. 9th Int’l Conf. Ubiquitous Computing (Ubicomp 07), ACM},
     publisher={Press},
     pages={271-288}
}
@article{RefWorks:40,
author =       {Andreas Reinhardt and Frank Englert and Delphine Christin},
year =       {2013},
title =       {Enhancing user privacy by preprocessing distributed smart meter data},
journal =       {2013 Sustainable Internet and ICT for Sustainability (SustainIT)},
pages =       {1-7},
note =       {The increasing presence of renewable sources requires power grid operators to continuously monitor electricity generation and demand in order to maintain the...},
abstract =       {The increasing presence of renewable sources requires power grid operators to continuously monitor electricity generation and demand in order to maintain the grid's stability. To this end, smart meters have been deployed to collect realtime information about the current grid load and forward it to the utility in a timely manner. High resolution smart meter data can however reveal the nature of appliances and their mode of operation with high accuracy, and thus endanger user privacy. In this paper, we investigate the impact on user privacy when the consumption data collected by distributed smart metering devices are preprocessed prior to their usage. We therefore assess the impact on the successful classification of appliances when sensor readings are (1) quantized, (2) down-sampled at a lower sampling rate, and (3) averaged by means of an FIR filter. Our evaluation shows that a combination of these preprocessing steps can provide a balanced trade-off that is in the interests of both users (privacy protection) and utilities (near real-time information).},
keywords =       {power grids; electricity generation; power grid operators; power engineering computing; renewable energy sources; Accuracy; smart meters; FIR filter; Feature extraction; data privacy; FIR filters; distributed smart meter data; electricity demand; Power demand; user privacy; Home appliances; Quantization (signal); Data preprocessing},
language =       {English}
}
@article{RefWorks:9,
author =       {Alexandra Simader and Bernhard Kluger and Nora Neumann and Christoph Bueschl and Marc Lemmens and Gerald Lirk and Rudolf Krska and Rainer Schuhmacher},
month =       {2015-10-24},
title =       {QCScreen: a software tool for data quality control in LC-HRMS based metabolomics},
url =       {http://www.biomedcentral.com/1471-2105/16/341},
note =       {Type: Software; Copyright 2015 Simader et al.},
abstract =       {Abstract Background Metabolomics experiments often comprise large numbers of biological samples resulting in huge amounts of data. This data needs to be inspected for plausibility before data evaluation to detect putative sources of error e.g. retention time or mass accuracy shifts. Especially in liquid chromatography-high resolution mass spectrometry (LC-HRMS) based metabolomics research, proper quality control checks (e.g. for precision, signal drifts or offsets) are crucial prerequisites to achieve reliable and comparable results within and across experimental measurement sequences. Software tools can support this process. Results The software tool QCScreen was developed to offer a quick and easy data quality check of LC-HRMS derived data. It allows a flexible investigation and comparison of basic quality-related parameters within user-defined target features and the possibility to automatically evaluate multiple sample types within or across different measurement sequences in a short time. It offers a user-friendly interface that allows an easy selection of processing steps and parameter settings. The generated results include a coloured overview plot of data quality across all analysed samples and targets and, in addition, detailed illustrations of the stability and precision of the chromatographic separation, the mass accuracy and the detector sensitivity. The use of QCScreen is demonstrated with experimental data from metabolomics experiments using selected standard compounds in pure solvent. The application of the software identified problematic features, samples and analytical parameters and suggested which data files or compounds required closer manual inspection. Conclusions QCScreen is an open source software tool which provides a useful basis for assessing the suitability of LC-HRMS data prior to time consuming, detailed data processing and subsequent statistical analysis. It accepts the generic mzXML format and thus can be used with many different LC-HRMS platforms to process both multiple quality control sample types as well as experimental samples in one or more measurement sequences.},
keywords =       {QC; LC-HRMS; Retention time shift; Mass accuracy shift; mzXML},
language =       {en}
}
@article{RefWorks:44,
     author={Jonathan Jones Spencer},
     year={2013},
     month={19/09/2013},
     title={Denmark – all homes to have smart electric meters by 2020},
     volume={2016},
     number={04/04},
     url={http://www.metering.com/denmark-all-homes-to-have-smart-electric-meters-by-2020/}
}
@article{RefWorks:29,
     author={D. Srinivasan and W. S. Ng and A. C. Liew},
     year={2006},
     title={Neural-network-based signature recognition for harmonic source identification},
     journal={IEEE Transactions on Power Delivery},
     volume={21},
     number={1},
     pages={398-405},
     note={This paper proposes a neural-network (NN)-based approach to nonintrusive harmonic source identification. In this approach, NNs are trained to extract important... Several NN-based classification models including multilayer perceptron (MLP), radial basis function (RBF) network, and support vector machines (SVM) with...},
     abstract={This paper proposes a neural-network (NN)-based approach to nonintrusive harmonic source identification. In this approach, NNs are trained to extract important features from the input current waveform to uniquely identify various types of devices using their distinct harmonic "signatures". Such automated, noninvasive device identification will be critical in future power-quality monitoring and enhancement systems. Several NN-based classification models including multilayer perceptron (MLP), radial basis function (RBF) network, and support vector machines (SVM) with linear, polynomial, and RBF kernels were developed for signature extraction and device identification. These models were trained and tested using spike train data gathered from the Fourier analysis of the input current waveform in the presence of multiple devices. The performance of these models was compared in terms of their accuracy, generalization ability, and noise tolerance limits. The results showed that MLPs and SVM were both able to determine the presence of devices based on their harmonic signatures with high accuracy. MLP was found to be the best signature identification method because of its low computational requirements and ability to extract the information necessary for highly accurate device identification.},
     keywords={harmonic source identification; radial basis function network; Power system modeling; Computerized monitoring; power quality enhancement; Support vector machine classification; RBF network; multilayer perceptrons; support vector machines; Fourier analysis; Artificial neural network (ANN); power quality monitoring; multilayer perceptron; signature identification; power supply quality; feature extraction; Data mining; neural network; Polynomials; power system harmonics; power engineering computing; spike train data; Power quality; Object recognition; radial basis function networks; power harmonics; signature recognition; Studies; Electric power systems; Neural networks; Usage; Harmonics (Electric waves)/Neural network models},
     isbn={0885-8977},
     language={English}
}
@article{RefWorks:14,
     author={D. J. Thomson and L. J. Lanzerotti and C. G. Maclennan},
     year={2001},
     title={Interplanetary magnetic field: Statistical properties and discrete modes},
     journal={Journal of Geophysical Research},
     volume={106},
     number={A8},
     pages={15941-15962},
     isbn={0148-0227},
     language={English}
}
@article{RefWorks:23,
     author={M. Weiss and A. Helfenstein and F. Mattern and T. Staake},
     year={2012},
     title={Leveraging smart meter data to recognize home appliances},
     booktitle={Pervasive Computing and Communications (PerCom), 2012 IEEE International Conference on},
     pages={190-197},
     note={ID: 1}
}